{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T15:12:28.798415Z",
     "iopub.status.busy": "2022-04-05T15:12:28.798169Z",
     "iopub.status.idle": "2022-04-05T15:12:29.561268Z",
     "shell.execute_reply": "2022-04-05T15:12:29.560504Z",
     "shell.execute_reply.started": "2022-04-05T15:12:28.798352Z"
    },
    "id": "czsEOLvXH7Ss",
    "outputId": "076ebe0c-ca90-4443-dc35-ebd0f695acbb"
   },
   "source": [
    "In this notebook I use the HuggingFace library to experiment with CANINE and BERT on hate speech detection task, to check the preformances of CANINE against noisy datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zq-OIrg5FXM6"
   },
   "source": [
    "# Installs/Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T15:12:29.564473Z",
     "iopub.status.busy": "2022-04-05T15:12:29.563776Z",
     "iopub.status.idle": "2022-04-05T15:12:38.458947Z",
     "shell.execute_reply": "2022-04-05T15:12:38.458145Z",
     "shell.execute_reply.started": "2022-04-05T15:12:29.564441Z"
    },
    "id": "EtIWkuh-GxO2",
    "outputId": "5631db90-19bb-46a1-cba6-8c0b4f23f3f4"
   },
   "outputs": [],
   "source": [
    "! pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T15:12:38.461679Z",
     "iopub.status.busy": "2022-04-05T15:12:38.461408Z",
     "iopub.status.idle": "2022-04-05T15:12:43.803304Z",
     "shell.execute_reply": "2022-04-05T15:12:43.802511Z",
     "shell.execute_reply.started": "2022-04-05T15:12:38.461643Z"
    },
    "id": "QWjvNrNiAWXN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import get_scheduler\n",
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxumloCnOn7P"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T15:12:43.805646Z",
     "iopub.status.busy": "2022-04-05T15:12:43.805346Z",
     "iopub.status.idle": "2022-04-05T15:12:48.441335Z",
     "shell.execute_reply": "2022-04-05T15:12:48.440496Z",
     "shell.execute_reply.started": "2022-04-05T15:12:43.805606Z"
    },
    "id": "8u_dQcImOnTa",
    "outputId": "3d18fa3d-6056-4fda-ba6b-d0087bd37faf"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"hate_speech_offensive\")\n",
    "\n",
    "def tokenize_function(tokenizer, input_field):\n",
    "    return lambda examples: tokenizer(examples[input_field], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lS-XQ4PtI_7H"
   },
   "source": [
    "# CANINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T01:42:53.11289Z",
     "iopub.status.busy": "2022-04-03T01:42:53.111026Z",
     "iopub.status.idle": "2022-04-03T01:43:11.023408Z",
     "shell.execute_reply": "2022-04-03T01:43:11.022608Z",
     "shell.execute_reply.started": "2022-04-03T01:42:53.112851Z"
    },
    "id": "48y-HKZLGmmK",
    "outputId": "d5caed03-0a0d-40ae-fb13-780930ef2c67"
   },
   "outputs": [],
   "source": [
    "\n",
    "from transformers import CanineTokenizer, CanineForSequenceClassification\n",
    "\n",
    "canine_tokenizer = CanineTokenizer.from_pretrained(\"google/canine-s\")\n",
    "canine = CanineForSequenceClassification.from_pretrained(\"google/canine-s\", num_labels=3)\n",
    "\"\"\"\n",
    "for name, param in canine.named_parameters():\n",
    "    if not('classifier' in name):\n",
    "        param.requires_grad = False\n",
    "\"\"\"\n",
    "inputs = canine_tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "outputs = canine(**inputs, labels=labels)\n",
    "print(outputs)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9rFQFtfJEtR"
   },
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T01:43:11.025435Z",
     "iopub.status.busy": "2022-04-03T01:43:11.024713Z",
     "iopub.status.idle": "2022-04-03T01:43:11.032351Z",
     "shell.execute_reply": "2022-04-03T01:43:11.031693Z",
     "shell.execute_reply.started": "2022-04-03T01:43:11.025396Z"
    },
    "id": "XUeM02fUJFUO",
    "outputId": "18099010-c08c-4bff-832d-45f0feb191fd"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "\n",
    "\"\"\"\n",
    "for name, param in bert.named_parameters():\n",
    "    if not('classifier' in name):\n",
    "        param.requires_grad = False\n",
    "\"\"\"\n",
    "inputs = bert_tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "outputs = bert(**inputs, labels=labels)\n",
    "print(outputs)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhPKiopM_ZPw"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T01:44:42.156256Z",
     "iopub.status.busy": "2022-04-03T01:44:42.155966Z",
     "iopub.status.idle": "2022-04-03T01:45:09.542352Z",
     "shell.execute_reply": "2022-04-03T01:45:09.541665Z",
     "shell.execute_reply.started": "2022-04-03T01:44:42.156225Z"
    },
    "id": "Rb_lPmh-HZC2",
    "outputId": "fbacc9da-5d9b-438d-c654-1c11e1d4c4d2"
   },
   "outputs": [],
   "source": [
    "# Select model\n",
    "model = canine\n",
    "tokenizer = canine_tokenizer\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 3e-4\n",
    "n_epochs = 20\n",
    "batch_size = 4\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Dataset parameter\n",
    "dataset_input_field = \"tweet\"\n",
    "dataset_label_field = \"class\"\n",
    "dataset_remove_columns = ['count','hate_speech_count', 'offensive_language_count', 'neither_count', 'tweet']\n",
    "# Tokenizer wraggling\n",
    "tokenized_datasets = dataset.map(tokenize_function(tokenizer, dataset_input_field), batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(dataset_remove_columns)\n",
    "tokenized_datasets = tokenized_datasets.rename_column(dataset_label_field, \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "tokenized_datasets = tokenized_datasets['train'].train_test_split(0.1) # Remove if already split into train/test\n",
    "\n",
    "\n",
    "# Loaders\n",
    "train_dataloader = torch.utils.data.DataLoader(tokenized_datasets[\"train\"], shuffle=True, batch_size=batch_size)\n",
    "test_dataloader = torch.utils.data.DataLoader(tokenized_datasets[\"test\"], batch_size=batch_size)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "n_training_steps = n_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=n_training_steps)\n",
    "acc = load_metric(\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T16:16:48.394425Z",
     "iopub.status.busy": "2022-03-31T16:16:48.394002Z",
     "iopub.status.idle": "2022-03-31T16:31:29.132538Z",
     "shell.execute_reply": "2022-03-31T16:31:29.129751Z",
     "shell.execute_reply.started": "2022-03-31T16:16:48.39439Z"
    },
    "id": "Cb72NQGS_5y1",
    "outputId": "5cad6fb3-0e5a-476d-a3fd-abfb8fd32e7d"
   },
   "outputs": [],
   "source": [
    "# Remove wandb dependency if not needed\n",
    "import wandb\n",
    "wandb.init(project=\"nlpmva\")\n",
    "wandb.watch(model)\n",
    "\n",
    "for k in range(n_epochs):\n",
    "    metrics = {}\n",
    "    # Train\n",
    "    model.train()\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        # Compute metrics\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        acc.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    metrics['train_acc'] = acc.compute()\n",
    "    \n",
    "    # Test\n",
    "    model.eval()\n",
    "    for batch in test_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        # Compute metrics\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        acc.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    metrics['test_acc'] = acc.compute()\n",
    "    \n",
    "    # log metrics\n",
    "    wandb.log(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
